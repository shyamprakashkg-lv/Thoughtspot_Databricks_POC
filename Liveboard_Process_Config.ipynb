{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff51bd84-ce18-45b6-899c-61ea8b3201e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## This notebook:\n",
    " 1. Reads TML files from a volume folder\n",
    " 2. Identifies all liveboards\n",
    " 3. Creates/updates a configuration table with dashboard name, GUID, and process flag (default: N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19736f1e-5a35-41f5-b5ea-ddaac0094b20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Configuration\n",
    "CATALOG = \"dbx_migration_poc\"\n",
    "SCHEMA = \"dbx_migration_ts\"\n",
    "TML_VOLUME = \"lv_dashfiles_ak/\"\n",
    "FOLDER = \"liveboard\"\n",
    "\n",
    "# Full path to TML files\n",
    "TML_PATH = f\"/Volumes/{CATALOG}/{SCHEMA}/{TML_VOLUME}/\"\n",
    "\n",
    "# Configuration table\n",
    "CONFIG_TABLE = f\"{CATALOG}.{SCHEMA}.liveboard_migration_config\"\n",
    "\n",
    "print(f\"Reading from: {TML_PATH}\")\n",
    "print(f\"Config table: {CONFIG_TABLE}\")\n",
    "\n",
    "\n",
    "\n",
    "def parse_tml_file(file_path):\n",
    "    \"\"\"Parse TML file (YAML or JSON)\"\"\"\n",
    "    try:\n",
    "        content = dbutils.fs.head(file_path, 10 * 1024 * 1024)\n",
    "        try:\n",
    "            return yaml.safe_load(content)\n",
    "        except yaml.YAMLError:\n",
    "            return json.loads(content)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error parsing file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Step 1: Read files from volume\n",
    "try:\n",
    "    all_files = dbutils.fs.ls(TML_PATH)\n",
    "    tml_files = [f.path for f in all_files if f.path.endswith(('.tml', '.yaml', '.json'))]\n",
    "    print(f\"Found {len(tml_files)} TML files\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Cannot read from {TML_PATH}\")\n",
    "    print(f\"Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 2: Identify liveboards\n",
    "liveboards = []\n",
    "\n",
    "for file_path in tml_files:\n",
    "    filename = Path(file_path).name\n",
    "    print(f\"Processing: {filename}\")\n",
    "    \n",
    "    tml_data = parse_tml_file(file_path)\n",
    "    \n",
    "    if tml_data and 'liveboard' in tml_data:\n",
    "        liveboard = tml_data['liveboard']\n",
    "        name = liveboard.get('name', filename.replace('.tml', '').replace('.yaml', '').replace('.json', ''))\n",
    "        guid = tml_data.get('guid', 'NO_GUID')\n",
    "        \n",
    "        liveboards.append({\n",
    "            'name': name,\n",
    "            'guid': guid,\n",
    "            'process_flag': 'N'\n",
    "        })\n",
    "        \n",
    "        print(f\"  ✓ Found liveboard: {name} ({guid})\")\n",
    "    else:\n",
    "        print(f\"  ✗ Not a liveboard or parse error\")\n",
    "\n",
    "print(f\"\\nTotal liveboards found: {len(liveboards)}\")\n",
    "\n",
    "# Step 3: Create table and insert entries\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")\n",
    "\n",
    "create_table_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CONFIG_TABLE} (\n",
    "    name STRING,\n",
    "    guid STRING,\n",
    "    process_flag STRING\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(create_table_sql)\n",
    "print(f\"✓ Table {CONFIG_TABLE} ready\")\n",
    "\n",
    "# Get existing GUIDs\n",
    "try:\n",
    "    existing_df = spark.sql(f\"SELECT guid FROM {CONFIG_TABLE}\").toPandas()\n",
    "    existing_guids = set(existing_df['guid'].tolist())\n",
    "    print(f\"Found {len(existing_guids)} existing entries\")\n",
    "except:\n",
    "    existing_guids = set()\n",
    "    print(\"No existing entries\")\n",
    "\n",
    "# Insert only new liveboards\n",
    "import pandas as pd\n",
    "\n",
    "new_liveboards = [lb for lb in liveboards if lb['guid'] not in existing_guids]\n",
    "\n",
    "if new_liveboards:\n",
    "    df = pd.DataFrame(new_liveboards)\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    spark_df.write.mode(\"append\").saveAsTable(CONFIG_TABLE)\n",
    "    print(f\"✓ Added {len(new_liveboards)} new liveboards\")\n",
    "else:\n",
    "    print(\"✓ No new liveboards to add\")\n",
    "\n",
    "# View Configuration Table\n",
    "display(spark.sql(f\"SELECT * FROM {CONFIG_TABLE} ORDER BY name\"))\n",
    "\n",
    "\n",
    "# Summary\n",
    "summary = spark.sql(f\"\"\"\n",
    "SELECT \n",
    "    process_flag,\n",
    "    COUNT(*) as count\n",
    "FROM {CONFIG_TABLE}\n",
    "GROUP BY process_flag\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== Summary ===\")\n",
    "display(summary)\n",
    "\n",
    "print(f\"\"\"\n",
    "Configuration table: {CONFIG_TABLE}\n",
    "\n",
    "To enable a dashboard:\n",
    "UPDATE {CONFIG_TABLE} \n",
    "SET process_flag = 'Y'\n",
    "WHERE name = 'Your Dashboard Name';\n",
    "\n",
    "To enable all:\n",
    "UPDATE {CONFIG_TABLE} \n",
    "SET process_flag = 'Y';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea52af7a-3f2e-448f-99df-624625ea2d62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "UPDATE dbx_migration_poc.dbx_migration_ts.liveboard_migration_config \n",
    "SET process_flag = 'Y'\n",
    "WHERE name = 'All_chart_Liveboard';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f813a42-e191-4ca3-b0f1-f641f876178e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from dbx_migration_poc.dbx_migration_ts.liveboard_migration_config "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8229436832473342,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Liveboard_Process_Config",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
